{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pageviewapi\n",
    "from datetime import datetime as dt\n",
    "import requests\n",
    "from attrdict import AttrDict\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as optimize\n",
    "import sklearn.metrics as metrics\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize the number of views for 400 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__version__   = \"0.4.0\"\n",
    "PROJECT_URL   = \"https://github.com/Commonists/pageview-api\"\n",
    "UA            = \"Python pageview-api client v{version} <{url}>\"\n",
    "USER_AGENT    = {'User-Agent': UA.format(url=PROJECT_URL, version=__version__)}\n",
    "API_BASE_URL  = \"https://wikimedia.org/api/rest_v1/metrics\"\n",
    "PA_ENDPOINT   = \"pageviews/per-article\"\n",
    "PA_ARGS       = \"{project}/{access}/{agent}/{page}/{granularity}/{start}/{end}\"\n",
    "\n",
    "def per_article(project, page, start, end,access='all-access', agent='all-agents', granularity='daily'):\n",
    "\n",
    "    args = PA_ARGS.format(project=project,page=page,start=start,end=end,access=access,agent=agent,granularity=granularity)\n",
    "    return __api__(PA_ENDPOINT, args)\n",
    "\n",
    "def __api__(end_point, args, api_url=API_BASE_URL):\n",
    "    \n",
    "    url = \"/\".join([api_url, end_point, args])\n",
    "    response = requests.get(url, headers=USER_AGENT)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    \n",
    "    elif response.status_code == 404:\n",
    "        print(\"error404:  \"+args)\n",
    "    \n",
    "    #elif response.status_code == 429:\n",
    "        #raise ThrottlingException\n",
    "    \n",
    "    else:\n",
    "        response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two Examples\n",
    "names=[\"2016_Kumamoto_earthquakes\",\"Alan_Rickman\"]\n",
    "start_dates=[\"2016-04-15\",\"2016-01-14\"]\n",
    "\n",
    "date_list =list(range(0, 400, 1))\n",
    "df_decay=pd.DataFrame(index=date_list)\n",
    "\n",
    "for name,date_str in zip(names,start_dates):\n",
    "    \n",
    "    start_date=datetime.datetime.strptime(date_str, '%Y-%m-%d')#イベント発生日\n",
    "    last_date=start_date+datetime.timedelta(days=399)\n",
    "\n",
    "    response=per_article('en.wikipedia', name, start_date.strftime('%Y%m%d'), last_date.strftime('%Y%m%d'), access='all-access', agent='user', granularity='daily')\n",
    "\n",
    "    if type(response)==dict:\n",
    "\n",
    "        if len(response['items'])==400:\n",
    "\n",
    "            page_view_lis=[]\n",
    "            for i in range(len(response['items'])):\n",
    "                page_view_lis.append(response['items'][i][\"views\"])\n",
    "\n",
    "            df_decay[name]=page_view_lis\n",
    "\n",
    "        else:#APIの取得に漏れがある\n",
    "            print(f\"not_enough:{name}\")\n",
    "\n",
    "    else:#responseなし\n",
    "        print(f\"not_response:{name}\")\n",
    "\n",
    "    df_decay[name]=page_view_lis\n",
    "#df_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[\"2016_Kumamoto_earthquakes\",\"Alan_Rickman\"]\n",
    "for name in names:\n",
    "    df=df_decay[name][:365]\n",
    "    x=np.linspace(1,365,365)#x\n",
    "    y=df.values#y\n",
    "    \n",
    "    fig=plt.figure()\n",
    "    \n",
    "    #log-log plot\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.scatter(x, y, s=10, c=\"black\")\n",
    "    \n",
    "    plt.xlabel(\"Days(since event occurrences)\",size=16)\n",
    "    plt.ylabel(\"Page views\",size=16)\n",
    "    \n",
    "    #grid\n",
    "    plt.grid(linewidth=0.2)\n",
    "    \n",
    "    #title\n",
    "    plt.title(f'{name}', loc='center',size=16)\n",
    "    \n",
    "    #グラフの保存\n",
    "    #fig.savefig(f\"C:/Users/naoki/OneDrive/デスクトップ/{file}.eps\")\n",
    "    \n",
    "    #グラフ描画\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting with same function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beki(x, A, a):\n",
    "    return np.log10( A * (x**(-a)) )\n",
    "\n",
    "def exp(x, A, a):\n",
    "    return np.log10( A * np.exp(-a*x))\n",
    "\n",
    "def biexp(x, A, a, B, b):\n",
    "    return np.log10( A * np.exp(-a*x) + B * np.exp(-b*x) )\n",
    "\n",
    "def stretch(x, a, b, c):\n",
    "    return np.log10( np.exp( -(x/a)**( b*x**(-c)) ) )\n",
    "\n",
    "def shiftbeki(x, a, b, c):\n",
    "    return np.log10( a * (x**(-b)) + c )\n",
    "\n",
    "def expbeki(x, A, a, B, b):\n",
    "    return np.log10( A *np.exp(-a*x)+ B*(x**(-b)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beki_nolog(x, A, a):\n",
    "    return A * (x**(-a))\n",
    "\n",
    "def exp_nolog(x, A, a):\n",
    "    return A * np.exp(-a*x)\n",
    "\n",
    "def biexp_nolog(x, A, a, B, b):\n",
    "    return A * np.exp(-a*x) + B * np.exp(-b*x)\n",
    "\n",
    "def stretch_nolog(x, a, b, c):\n",
    "    return np.exp( -(x/a)**( b*x**(-c)) )\n",
    "\n",
    "def shiftbeki_nolog(x, a, b, c):\n",
    "    return a * (x**(-b)) + c \n",
    "\n",
    "def expbeki_nolog(x, A, a, B, b):\n",
    "    return A *np.exp(-a*x)+ B*(x**(-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[\"2016_Kumamoto_earthquakes\",\"Alan_Rickman\"]\n",
    "\n",
    "for name in names:\n",
    "    \n",
    "    df=df_decay[name]\n",
    "    df_fromax=df[df.idxmax():]\n",
    "    minimum = np.min(df_fromax.values[np.nonzero(df_fromax.values)])\n",
    "    df=df_fromax+minimum\n",
    "    df_norm=df/df.max()\n",
    "    df_norm.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    y_analysis=np.log10(df_norm)\n",
    "    x_analysis = np.linspace(1,len(y_analysis),len(y_analysis))\n",
    "    \n",
    "    popt_beki, _      = optimize.curve_fit(beki, x_analysis, y_analysis, bounds=((0,0),(np.inf,np.inf)) )\n",
    "    popt_exp, _       = optimize.curve_fit(exp, x_analysis, y_analysis, bounds=((0,0),(np.inf,np.inf)) )\n",
    "    popt_biexp, _     = optimize.curve_fit(biexp, x_analysis, y_analysis, bounds=((0,0,0,0),(np.inf,np.inf,np.inf,np.inf)))\n",
    "    popt_stretch, _   = optimize.curve_fit(stretch, x_analysis, y_analysis, bounds=((0,0,0),(np.inf,np.inf,np.inf)))\n",
    "    popt_shiftbeki, _ = optimize.curve_fit(shiftbeki, x_analysis, y_analysis, bounds=((0,0,0),(np.inf,np.inf,np.inf)))\n",
    "    popt_expbeki, _ = optimize.curve_fit(expbeki, x_analysis, y_analysis, bounds=((0,0,0,0),(np.inf,np.inf,np.inf,np.inf)))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(x_analysis,df_norm.values,marker='.',s=10, c=\"black\")\n",
    "    plt.grid(linewidth=0.2)\n",
    "    plt.title(f'{name}', loc='center',size=16)\n",
    "    \n",
    "    plt.plot(x_analysis,beki_nolog(x_analysis,popt_beki[0],popt_beki[1]),linestyle = \"dashdot\", label = \"power-law\", color = \"red\",alpha = 1)\n",
    "    plt.plot(x_analysis,exp_nolog(x_analysis,popt_exp[0],popt_exp[1]),linestyle = \"dashed\", label = \"Exponential\", color = \"blue\",alpha = 1)\n",
    "    plt.plot(x_analysis,expbeki_nolog(x_analysis,popt_expbeki[0],popt_expbeki[1],popt_expbeki[2],popt_expbeki[3]),linestyle = \"solid\", label = \"proposed model\", linewidth = 4, color = \"orange\",alpha = 0.7)\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(0.95, 0.95), loc='upper right', borderaxespad=0.5, fontsize=12)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(r\"Days (since peak $t_{c}$)\",size=12)\n",
    "    plt.ylabel(r\"Normalized page views\",size=12)\n",
    "    plt.tick_params(axis='y', which='major', labelsize=13)\n",
    "    plt.tick_params(axis='x', which='major', labelsize=13)\n",
    "    \n",
    "    #グラフの保存\n",
    "    #fig.savefig(f\"C:/Users/naoki/OneDrive/デスクトップ/figure_work/3fit.eps\")\n",
    "    \n",
    "    #グラフ描画\n",
    "    plt.show()\n",
    "    print(f\"beta:{popt_expbeki[1]},alpha:{popt_expbeki[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MemorySwitchingPoint(example)\n",
    "file=\"disaster\"\n",
    "name=\"2016_Kumamoto_earthquakes\"\n",
    "\n",
    "df=df_decay[name]\n",
    "df_fromax=df[df.idxmax():]\n",
    "minimum = np.min(df_fromax.values[np.nonzero(df_fromax.values)])\n",
    "df=df_fromax+minimum\n",
    "df_norm=df/df.max()\n",
    "df_norm.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y_analysis=np.log10(df_norm)\n",
    "x_analysis = np.linspace(1,len(y_analysis),len(y_analysis))\n",
    "\n",
    "popt_expbeki, _ = optimize.curve_fit(expbeki, x_analysis, y_analysis, bounds=((0,0,0,0),(np.inf,np.inf,np.inf,np.inf)))\n",
    "\n",
    "fig=plt.figure(figsize=(15, 4))\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "ax3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "ax1.grid(linewidth=0.2)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim(0.001,2)\n",
    "ax1.plot(x_analysis,beki_nolog(x_analysis,popt_expbeki[2],popt_expbeki[3]),linestyle = \"dashdot\", label = \"power-law\", color = \"red\",alpha = 1)\n",
    "ax1.plot(x_analysis,exp_nolog(x_analysis,popt_expbeki[0],popt_expbeki[1]),linestyle = \"dashed\", label = \"Exponential\", color = \"blue\",alpha = 1)\n",
    "ax1.plot(x_analysis,expbeki_nolog(x_analysis,popt_expbeki[0],popt_expbeki[1],popt_expbeki[2],popt_expbeki[3]),linestyle = \"solid\", label = \"proposed model\", linewidth = 4, color = \"orange\",alpha = 0.7)\n",
    "ax1.set_xlabel(r\"Days (since peak $t_{c}$)\",size=10)\n",
    "ax1.set_ylabel(r\"Normalized page views\",size=10)\n",
    "\n",
    "ax2.grid(linewidth=0.2)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylim(0.001,2)\n",
    "ax2.plot(x_analysis,exp_nolog(x_analysis,popt_expbeki[0],popt_expbeki[1]),linestyle = \"dashed\", label = \"Exponential\", color = \"blue\",alpha = 1)\n",
    "ax2.set_xlabel(r\"Days (since peak $t_{c}$)\",size=10)\n",
    "\n",
    "ax3.grid(linewidth=0.2)\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_yscale('log')\n",
    "ax3.set_ylim(0.001,2)\n",
    "ax3.plot(x_analysis,beki_nolog(x_analysis,popt_expbeki[2],popt_expbeki[3]),linestyle = \"dashdot\", label = \"power-law\", color = \"red\",alpha = 1)\n",
    "ax3.set_xlabel(r\"Days (since peak $t_{c}$)\",size=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MemorySwitchingPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Big Figure######\n",
    "left = x_analysis.tolist()[:30]\n",
    "pop = np.array([beki_nolog(x_analysis,popt_expbeki[2],popt_expbeki[3]).tolist()[:30],exp_nolog(x_analysis,popt_expbeki[0],popt_expbeki[1]).tolist()[:30]])\n",
    "\n",
    "#Stacked graph\n",
    "fig = plt.figure()\n",
    "axes1 = fig.add_axes([0.1, 0.1, 0.8, 0.8]) #size\n",
    "color_lis=[\"tomato\",\"royalblue\"]#色指定\n",
    "for i,color in zip(range(pop.shape[0]),color_lis):\n",
    "    axes1.bar(left, pop[i],bottom = np.sum(pop[:i], axis = 0),width=0.5, edgecolor='k', linewidth=1,color=color)\n",
    "\n",
    "#curve\n",
    "axes1.plot(x_analysis[:30],expbeki_nolog(x_analysis[:30],popt_expbeki[0],popt_expbeki[1],popt_expbeki[2],popt_expbeki[3])[:30],linestyle = \"solid\", label = \"proposed model\", linewidth = 4, color = \"orange\",alpha = 0.7)\n",
    "axes1.legend([\"our model\",\"power-law\", \"exponential\"], loc='upper left',bbox_to_anchor=(0.09, 0.96))\n",
    "#axes1.set_yscale(\"log\")\n",
    "axes1.grid(linewidth=0.2)\n",
    "plt.xlabel(r\"Days (since peak $t_{c}$)\",size=10)\n",
    "plt.ylabel(\"Normalized page views\",size=10)\n",
    "\n",
    "#####Small Figure######\n",
    "left2 = x_analysis.tolist()[7:12]\n",
    "pop2 = np.array([beki_nolog(x_analysis,popt_expbeki[2],popt_expbeki[3]).tolist()[7:12],exp_nolog(x_analysis,popt_expbeki[0],popt_expbeki[1]).tolist()[7:12]])\n",
    "axes2 = fig.add_axes([0.5, 0.25, 0.35, 0.6]) \n",
    "\n",
    "#Stacked graph\n",
    "color_lis=[\"tomato\",\"royalblue\"]\n",
    "for i,color in zip(range(pop2.shape[0]),color_lis):#shapeでサイズを知れる\n",
    "    axes2.bar(left2, pop2[i],bottom = np.sum(pop2[:i], axis = 0),width=0.5, edgecolor='k', linewidth=1,color=color)\n",
    "\n",
    "#Auxiliary characters\n",
    "axes2.text(10.7,0.14,\"t*\", fontsize=20)\n",
    "axes2.text(10.7,0.12,\"↓\", fontsize=20)\n",
    "\n",
    "#Auxiliary line\n",
    "axes2.hlines([(pop2[0][0]+pop2[1][0])/2], 7.5, 8.5, \"black\", linestyles='solid', label = \"50% line\")\n",
    "axes2.hlines([(pop2[0][1]+pop2[1][1])/2], 8.5, 9.5, \"black\", linestyles='solid')\n",
    "axes2.hlines([(pop2[0][2]+pop2[1][2])/2], 9.5, 10.5, \"black\", linestyles='solid')\n",
    "axes2.hlines([(pop2[0][3]+pop2[1][3])/2], 10.5, 11.5, \"black\", linestyles='solid')\n",
    "axes2.hlines([(pop2[0][4]+pop2[1][4])/2], 11.5, 12.5, \"black\", linestyles='solid')\n",
    "axes2.legend()\n",
    "\n",
    "#グラフの保存\n",
    "#fig.savefig(f\"C:/Users/naoki/OneDrive/デスクトップ/figure_work/memorypoint.eps\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
